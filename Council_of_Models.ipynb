{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will compare the performance of these models:\n",
    "\n",
    "RDN, RRDN, EDSR, SRGAN, RealESRGAN, CycleGAN, DRCT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.image import ssim, psnr\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "from istari_tools import (display_image_pair,\n",
    "                          calculate_metrics,\n",
    "                          create_dataset,\n",
    "                          load_and_preprocess_valid_data)\n",
    "from mithril_sharp import (residual_block,\n",
    "                           build_rdn,\n",
    "                           build_rrdn,\n",
    "                           build_edsr,\n",
    "                           build_srgan_generator,\n",
    "                           build_real_esrgan_generator,\n",
    "                           build_cyclegan_generator,\n",
    "                           build_drct_decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_dir = './data/DIV2K_train_LR_bicubic_X4_extracted/DIV2K_train_LR_bicubic/X4'\n",
    "hr_dir = './data/DIV2K_train_HR_extracted/DIV2K_train_HR'\n",
    "\n",
    "test_lr_dir = './data/DIV2K_valid_LR_bicubic_X4_extracted/DIV2K_valid_LR_bicubic/X4'\n",
    "test_hr_dir = './data/DIV2K_valid_HR_extracted/DIV2K_valid_HR'\n",
    "\n",
    "# parameters\n",
    "batch_size = 16\n",
    "image_size = 128\n",
    "scale_factor = 4\n",
    "num_channels = 3\n",
    "\n",
    "num_test_images = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lr_paths = sorted(os.listdir(test_lr_dir))[:num_test_images]\n",
    "test_hr_paths = sorted(os.listdir(test_hr_dir))[:num_test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builders = [build_rdn, build_rrdn, build_edsr, build_srgan_generator, build_real_esrgan_generator,\n",
    "                build_cyclegan_generator, build_drct_decoder]\n",
    "model_names = ['RDN', 'RRDN', 'EDSR', 'SRGAN', 'RealESRGAN', 'CycleGAN', 'DRCT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Model', 'Train_Loss', 'Train_PSNR', 'Train_SSIM', \n",
    "                                   'Test_Loss', 'Test_PSNR', 'Test_SSIM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataset\n",
    "test_lr_images = sorted([os.path.join(test_lr_dir, f) for f in os.listdir(test_lr_dir)])[:num_test_images]\n",
    "test_hr_images = sorted([os.path.join(test_hr_dir, f) for f in os.listdir(test_hr_dir)])[:num_test_images]\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_lr_images, test_hr_images))\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda x, y: load_and_preprocess_valid_data(x, y, image_size, scale_factor),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RDN model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Inputs have incompatible shapes. Received shapes (32, 32, 64) and (32, 32, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_builder, model_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(model_builders, model_names):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m model...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# define loss and optimizer\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     loss_fn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mMeanSquaredError()\n",
      "File \u001b[0;32m~/Documents/github/Super_Resolution/mithril_sharp.py:35\u001b[0m, in \u001b[0;36mbuild_rdn\u001b[0;34m(image_size, num_blocks, growth_rate, num_channels, scale_factor)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Dense blocks\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_blocks):\n\u001b[0;32m---> 35\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mresidual_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrowth_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Global context feature fusion\u001b[39;00m\n\u001b[1;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n",
      "File \u001b[0;32m~/Documents/github/Super_Resolution/mithril_sharp.py:24\u001b[0m, in \u001b[0;36mresidual_block\u001b[0;34m(inputs, filters, kernel_size, use_bias)\u001b[0m\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(filters, kernel_size, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, use_bias\u001b[38;5;241m=\u001b[39muse_bias)(x)\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mBatchNormalization()(x)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/env/super_res/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/env/super_res/lib/python3.12/site-packages/keras/src/layers/merging/base_merge.py:93\u001b[0m, in \u001b[0;36mMerge._compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[0;32m---> 93\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs have incompatible shapes. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         output_shape\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(output_shape)\n",
      "\u001b[0;31mValueError\u001b[0m: Inputs have incompatible shapes. Received shapes (32, 32, 64) and (32, 32, 32)"
     ]
    }
   ],
   "source": [
    "for model_builder, model_name in zip(model_builders, model_names):\n",
    "    print(f'Training {model_name} model...')\n",
    "    model = model_builder(image_size, num_channels=num_channels, scale_factor=scale_factor)\n",
    "\n",
    "    # define loss and optimizer\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "    model.compile(loss=loss_fn, optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "    train_dataset = create_dataset(lr_dir, hr_dir, image_size, scale_factor)\n",
    "\n",
    "    epochs = 50\n",
    "    for epoch in range(epochs):\n",
    "        for lr_batch, hr_batch in train_dataset:\n",
    "            with tf.GradientTape() as tape:\n",
    "                sr_batch = model(lr_batch)\n",
    "                loss = loss_fn(hr_batch, sr_batch)\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # print progress every few epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f'Epoch: {epoch + 1}/{epochs}, Loss: {loss.numpy()}')\n",
    "\n",
    "    print('Evaluating the model...')\n",
    "\n",
    "    train_metrics = {'Loss': [], 'PSNR': [], 'SSIM': []}\n",
    "    for lr_batch, hr_batch in train_dataset.take(10):  # Take 10 batches for evaluation\n",
    "        sr_batch = model(lr_batch)\n",
    "        loss = loss_fn(hr_batch, sr_batch)\n",
    "        metrics = calculate_metrics(hr_batch, sr_batch)\n",
    "        \n",
    "        train_metrics['Loss'].append(float(loss))\n",
    "        train_metrics['PSNR'].append(metrics['PSNR'])\n",
    "        train_metrics['SSIM'].append(metrics['SSIM'])\n",
    "    \n",
    "    # Evaluate on test data\n",
    "    test_metrics = {'Loss': [], 'PSNR': [], 'SSIM': []}\n",
    "    for lr_batch, hr_batch in test_dataset.take(10):\n",
    "        sr_batch = model(lr_batch)\n",
    "        loss = loss_fn(hr_batch, sr_batch)\n",
    "        metrics = calculate_metrics(hr_batch, sr_batch)\n",
    "        \n",
    "        test_metrics['Loss'].append(float(loss))\n",
    "        test_metrics['PSNR'].append(metrics['PSNR'])\n",
    "        test_metrics['SSIM'].append(metrics['SSIM'])\n",
    "    \n",
    "    # Add results to DataFrame\n",
    "    results_df = results_df.append({\n",
    "        'Model': model_name,\n",
    "        'Train_Loss': np.mean(train_metrics['Loss']),\n",
    "        'Train_PSNR': np.mean(train_metrics['PSNR']),\n",
    "        'Train_SSIM': np.mean(train_metrics['SSIM']),\n",
    "        'Test_Loss': np.mean(test_metrics['Loss']),\n",
    "        'Test_PSNR': np.mean(test_metrics['PSNR']),\n",
    "        'Test_SSIM': np.mean(test_metrics['SSIM'])\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    eval_lr_batch, eval_hr_batch = next(iter(train_dataset))\n",
    "    eval_sr_batch = model.predict(eval_lr_batch)\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(eval_lr_batch[0])\n",
    "    plt.title('Low-Resolution Input')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(eval_sr_batch[0])\n",
    "    plt.title(f'{model_name} Output')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(eval_hr_batch[0])\n",
    "    plt.title('High-Resolution Ground Truth')\n",
    "    plt.show()\n",
    "\n",
    "    model.save(f'{model_name}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparative metrics\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# PSNR comparison\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.bar(results_df['Model'], results_df['Test_PSNR'])\n",
    "plt.title('PSNR Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# SSIM comparison\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.bar(results_df['Model'], results_df['Test_SSIM'])\n",
    "plt.title('SSIM Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Loss comparison\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.bar(results_df['Model'], results_df['Test_Loss'])\n",
    "plt.title('Loss Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "super_res",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
